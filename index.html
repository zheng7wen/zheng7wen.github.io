<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>zheng7wen</title>
  
  <meta name="author" content="Qiwen Zheng">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="image/panda.png">
</head>

  <body>
  <table width="950" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="67%" valign="middle">
        <p align="center">
          <name>Qiwen Zheng &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
		  </name>
        </p>
		<p>My name is Qiwen Zheng, currently a postgraduate at Computer Vision Institute, Shenzhen University, supervised by Prof. <a href="https://scholar.google.com/citations?user=AZ_y9HgAAAAJ&hl=en">Linlin Shen</a>. My research interests focus on Weakly Supervised Learning, especially <font color='blue'>Weakly Supervised Object Localization (WSOL) and Semantic Segmentation (WSSS) </font>. I also like to explore <font color='blue'>Unsupervised Learning </font> and <font color='blue'> Vision + Language </font> learning for object localization or semantic segmentation.
		</p>

        <p align=center>
          <a href="qiwen@hunnu.edu.cn">Email</a> &nbsp/&nbsp
          <a href=" ">CV</a> &nbsp/&nbsp
		  <a href="">Google Scholar</a>  &nbsp/&nbsp
          <a href="https://github.com/zheng7wen">Github</a> 

        </p>

        </td>
        <td width="100%">
        <img src="image/kinhane_2.jpeg" width="350">
        </td>
      </tr>
      </table>


<p></p><p></p><p></p><p></p>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>News</heading>
          <p>
		  <li> <strongsmall>[2021/10]</strongsmall> &nbsp;&nbsp;<smalll>2 papers was accepted by Biosensors-Basel.</smalll><br/>
		  <li> <strongsmall>[2022/09]</strongsmall> &nbsp;&nbsp;<smalll>1 paper is being published in Chinese Physics B. </smalll><br/>
		 
          
          </p>
        </td>
      </tr>
</table>




  <!--<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr>
    <td width="100%" valign="middle">
      <heading>Education</heading>
    </td>
  </tr>
  </table>
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr>
      <td width="10%">
        <img src='image/szu_icon.png' width="100">
      </td>
      <td width="75%" valign="middle">
      <p>
      <stronghuge>Hunan Normal University, China</stronghuge><br />
      Electronic Information Science and Technology  &nbsp;&nbsp;&nbsp;&nbsp; &bull; Sep. 2018 - Jun. 2022 <br />
      Supervisors: Prof. Leyong Jiang.</a>
      </p>
    </td>
  </tr>
  
  </table>
<p></p><p></p><p></p><p></p><p></p>
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr>
    <td width="100%" valign="middle">
      <heading>Research Experience</heading>
    </td>
  </tr>
  </table>
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr>
      <td width="10%">
        <a href="https://mreallab.github.io/people.html">
        <img src='image/jarvis_icon.png' width="100">
      </a>
      </td>
      <td width="80%" valign="middle">
      <p>
      <stronghuge>Jarvis Lab, Tencent</stronghuge><br />
      <huge><em>Research  Internship</em></huge>&nbsp;&nbsp;&nbsp;&nbsp; &nbsp; &bull; Dec. 2021 - Present <br />
      Advisors: &nbsp; Dr. <a href="https://scholar.google.com/citations?hl=en&user=WsKu4EMAAAAJ&view_op=list_works&sortby=pubdate">Yuexiang Li</a>
      </p>
    </td>
  </tr>-->
  


<p></p><p></p>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Publication <a href="https://scholar.google.com/citations?user=smbRMokAAAAJ&hl=en" style="font-size:22px;">[Google Scholar] 
        </td>
      </tr>
      </table>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" >
      <td width="15%">
        <img src='project/decoupled_mixup2.png'  width="200" height="150">
      </td>
      <td valign="top" width="75%">
	 <strong>Theoretical Model for a Highly Sensitive Near Infrared Biosensor Based on Bloch Surface Wave with Dirac Semimetal </strong><br>
 	 <strong>Qiwen Zheng</strong>,
	 <a>Yamei Liu</a>,
	 <a>Wenguang Lu</a>,
	 <a>Xiaoyu Dai</a>,
   <a>Haishan Tian</a>,
	 <a>Leyong Jiang</a><br>
 	 
   <em><strong>Biosensors 2021, 11</strong></em><br>
   <em> Institute: Hunan Normal University, National University of Defense Technology, Hunan University</em><br>
		
		<a href="https://doi.org/10.3390/bios11100390">[Paperlink]</a>, <a href=" ">[Code]</a><br>
        <em>Area: Out-of-Distribution Visual Recognition.</em> <br>
        <p></p>
			  <p>We propose a novel "Decoupled-Mixup" method to train CNN models for OOD visual recognition, which considers discriminative and noise-prone regions in
frequency-based and context-based fashion. </p>
      </td>
    </tr>
</table>    
	    
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" >
      <td width="15%">
        <img src='project/pbc.png'  width="200" height="150">
      </td>
      <td valign="top" width="75%">
	 <strong>Point Beyond Class: A Benchmark for Weakly Semi-Supervised Abnormality Localization in Chest X-Rays </strong><br>
	 <a>Haoqin Ji<sup>&#8224;</sup></a>,
 	 <a>Haozhe Liu<sup>&#8224;</sup></a>,  
	 <strong>Jinheng Xie</strong>,
	 <a>Yuexiang Li</a>,
	 <a>Nanjun He</a>,
         <a>Linlin Shen</a>,
	 <a>Yefeng Zheng</a>,
 	 <a>etal. </a><br>
 	 
   <em>International Conference on Medical Image Computing and Computer-Assisted Intervention, <strong>MICCAI 2022</strong></em><br>
		
		<a href="">[Paperlink]</a>, <a href="https://github.com/HaozheLiu-ST/Point-Beyond-Class">[Code]</a><br>
        <em>Area: Weakly semi-supervised abnormality localization.</em> <br>
        <p></p>
			  <p>We proposed a benchmark for weakly semi-supervised abnormality localization in Chest X-Rays. </p>
      </td>
    </tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" >
      <td width="15%">
        <img src='project/clims.png'  width="200" height="150">
      </td>
      <td valign="top" width="75%">
	 <strong>CLIMS: Cross Language Image Matching for Weakly Supervised Semantic Segmentation</strong><br>
	 <strong>Jinheng Xie</strong>,
	 <a>Xianxu Hou</a>,
 	 <a>Kai Ye</a>,  
 	 <a>Linlin Shen</a><br>
 	 
   <em>IEEE International Conference on Computer Vision and Pattern Recognition, <strong>CVPR 2022</strong></em><br>
		
		<a href="https://arxiv.org/abs/2203.02668">[Paperlink]</a>, <a href="https://github.com/CVI-SZU/CLIMS">[Code]</a><br>
        <em>Area: Weakly Supervised Semantic Segmentation, Vision Language Model.</em> <br>
        <p></p>
			  <p>We proposed a cross language image matching framework for WSSS (CLIMS), which
					can efficiently handle the problem of underestimation
					of complete object contents and unnecessary activation
					of closely-related background regions.</p>
      </td>
    </tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" >
      <td width="15%">
        <img src='project/ccam.png'  width="200" height="150">
      </td>
      <td valign="top" width="75%">
	 <strong>C2AM: Contrastive Learning of Class-agnostic Activation Map for Weakly Supervised Object Localization and Semantic Segmentation</strong><br>
	 <strong>Jinheng Xie</strong>,
	 <a>Jianfeng Xiang</a>,
 	 <a>Junliang Chen</a>,  
 	 <a>Xianxu Hou</a>,
 	 <a>Xiaodong Zhao</a>,
 	 <a>Linlin Shen</a><br>
 	 
   <em>IEEE International Conference on Computer Vision and Pattern Recognition, <strong>CVPR 2022</strong></em><br>
		
		<a href="https://arxiv.org/pdf/2203.13505.pdf">[Paperlink]</a>, <a href="https://github.com/CVI-SZU/CCAM">[Code]</a><br>
        <em>Area: Weakly Supervised Object Localization and Semantic Segmentation, Contrastive Learning.</em> <br>
        <p></p>
		<p>We proposed cross-image foreground-background contrast
			for class-agnostic activation maps generation using unlabeled
			image data. Class-agnostic activation map determines
			more reliable foreground regions, which can be used
			to replace or refine CAM for better WSOL and WSSS performance.</p>
      </td>
    </tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" >
      <td width="15%">
        <img src='project/attack.png'  width="200" height="150">
      </td>
      <td valign="top" width="75%">
	 <strong>Frequency-driven Imperceptible Adversarial Attack on Semantic Similarity</strong><br>
	 <a>Cheng Luo</a>,
 	 <a>Qinliang Lin</a>,  
 	 <a>Weicheng Xie</a>,  
 	 <a>Bizhu Wu</a>,  
 	 <strong>Jinheng Xie</strong>,
 	 <a>Linlin Shen</a><br>
 	 
   <em>IEEE International Conference on Computer Vision and Pattern Recognition, <strong>CVPR 2022</strong></em><br>
		
		<a href=" ">[Paperlink]</a>, <a href=" ">[Code]</a><br>
        <em>Area: Adversarial Attack, Contrastive Learning.</em> <br>
        <p></p>
		<!--<p>We introduce</p>-->
      </td>
    </tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" >
      <td width="15%">
        <img src='project/ornet.png'  width="200" height="150">
      </td>
      <td valign="top" width="75%">
	 <strong>Online Refinement of Low-level Feature Based Activation Map for Weakly Supervised Object Localization</strong><br>
	 <strong>Jinheng Xie</strong>,
	 <a>Cheng Luo</a>,
 	 <a>Xiangping Zhu</a>,  
 	 <a>Ziqi Jin</a>,
 	 <a>Weizeng Lu</a>,
 	 <a>Linlin Shen</a><br>
 	 
   <em>IEEE International Conference on Computer Vision, <strong>ICCV 2021</strong></em><br>
		
		<a href="https://arxiv.org/abs/2110.05741">[Paperlink]</a>, <a href="https://github.com/Sierkinhane/ORNet">[Code]</a><br>
        <em>Area: Weakly Supervised Object Localization, CAM. </em> <br>
        <p></p>
		<!--<p>We introduce</p>-->
      </td>
    </tr>
</table>

<!--<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" >
      <td width="15%">
        <img src='project/tab.png'  width="200" height="150">
      </td>
      <td valign="top" width="75%">
	 <strong>Think about boundary: Fusing multi-level boundary information for landmark heatmap regression</strong><br>
	 <strong>Jinheng Xie</strong>,
	 <a>Jun Wan</a>,
 	 <a>Linlin Shen</a>,
 	 <a>Zhihui Lai</a><br>
 	 
   <em>International Joint Conference on Neural Networks, <strong>IJCNN 2021</strong></em><br>
		
		<a href=" ">[Paperlink]</a>, <a href=" ">[Code]</a><br>
        <em>Area: Face Alignment. </em> <br>
        <p></p>
	<p>We introduce</p>
      </td>
    </tr>
</table>-->


<p></p><p></p><p></p><p></p><p></p>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Academic Service</heading>
          <div style="line-height:25px">
          <p>
		  <li> <stronghuge>Conference Reviwer:</stronghuge> &nbsp; CVPR'22&nbsp; AAAI'23<br/>
          </p>
          </div>
        </td>
      </tr>
</table>


<p></p><p></p><p></p><p></p><p></p>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Honors & Scholarships</heading>
          <div style="line-height:25px">
          <p>
		  <li> <stronghuge>Excellent Contributor Award </stronghuge> (Ascend All Wisdom Plan, <strong>HUAWEI</strong>),&nbsp; 2021 <br/>
		  <li> <stronghuge>China National Scholarship </stronghuge> (Rate <= 0.02%),&nbsp; 2020 - 2021<br/>
                  <li> <stronghuge>Excellent Academic Scholarship, First Class. </stronghuge>,&nbsp; 2020 - 2021<br/>
          </p>
          </div>
        </td>
      </tr>
</table>




   <p></p><p></p><p></p><p></p><p></p>
	 <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=250&t=n&d=lADcEbQ2Hou9upTL6suakF_JIL8FYgA4ipDfphDjFr0'></script>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
			<tbody><tr>
				<td>
				<br>
				<p align="left"><font size="2">
				Last updated on Aug. 24th, 2022
				<p align="middle"><font size="2">
				This awesome template borrowed from <a href="https://people.eecs.berkeley.edu/~barron/">here</a> and <a href="https://github.com/Wangt-CN/Wangt-CN.github.io">here</a>.
				</tbody></table>
</body>
</html>
Footer
